{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hey You"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yes You"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Comments and Directions !!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I mean, ... they are directly inline in the document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It is very easy to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just read them before coming to me ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## also ... Google is your friend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get an error of the form: <br><br>`ModuleNotFoundError: No module named ...` <br><br> then you need to install that package, and possibly update it as well.\n",
    "The script imports.sh should help install and update everything for you, but if there was something missed and you need to install it, first try: <br><br> `conda install name-of package` <br><br> If that doesn't work, try <br><br> `./[path to your anaconda3 directory]/bin/pip install name-of-package` <br><br> (obviously substituting the path for your anaconda directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage as sk\n",
    "from skimage import measure\n",
    "from timeit import default_timer as timer\n",
    "from scipy.spatial import ConvexHull\n",
    "from functools import reduce\n",
    "\n",
    "from enum import Enum\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "import dask.dataframe as dd\n",
    "import resource\n",
    "import holoviews as hv\n",
    "import datashader as ds\n",
    "import time\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "hv.notebook_extension()\n",
    "hv.extension('bokeh')\n",
    "from holoviews.operation.datashader import aggregate, datashade, dynspread, shade\n",
    "\n",
    "from datashader import transfer_functions as tf\n",
    "from colorcet import fire, gray, b_cyclic_wrwbw_40_90_c42\n",
    "from holoviews.operation.datashader import datashade\n",
    "\n",
    "from mothermachine.abstract_mother_machine_file import AbstractMotherMachineFile\n",
    "from mothermachine.plot_conn_comp_settings import PlotConnCompSettings\n",
    "from mothermachine.plot_conn_comp_results import PlotConnCompResults\n",
    "from mothermachine.tools import make_cell_montage\n",
    "from mothermachine.mm_file_io import save_properties, load_properties, detect_image_directories, find_shared_lane_pos_time_indcs\n",
    "\n",
    "from mothermachine.segmentation.extract import extract_connected_components_standard, extract_cells\n",
    "from mothermachine.segmentation.cleanup import select_cells_in_trenches, select_reasonable_cells\n",
    "from mothermachine.segmentation.lineages import sort_cells_into_lineages, determine_position_of_cell_in_trench, create_linear_index\n",
    "from mothermachine.segmentation.trenchlocs import TrenchLocs\n",
    "from mothermachine.post_cluster_analysis import stack_mother_properties, unstack_mother_properties, add_mother_property, find_peaks\n",
    "from mothermachine.analyze_division import  calculate_and_append_divisions, cleanup_lengths\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (18.0, 8.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Segementation File Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Abstract Class AbstractMotherMachineFile must be defined to allow file-names to be generated on the fly when supplied with a lane_num, pos_num and t_frame. You will need to define it for at least the Segmentation file but also for any fluorescent images that aren't used for segmentation. See examples below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you may need to change this depending on your operating-system type\n",
    "example_base_dir = \"/run/user/1001/gvfs/smb-share:server=research.files.med.harvard.edu,share=sysbio/PAULSSON LAB/MotherMachinePython/sample_images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load example files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. I want to run [Example 1](#Example-1).\n",
    "2. No, I want to run [Example 2](#Example-2).\n",
    "3. No, I want to analyze my old data [Load Old Data](#load-old-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basedir = os.path.join(example_base_dir,'example1')\n",
    "\n",
    "def generate_save_directory(lane_num):\n",
    "    save_dir = os.path.join(basedir, \"Lane{0:0>1}\".format(lane_num))\n",
    "    return save_dir\n",
    "\n",
    "class MotherMachineFile(AbstractMotherMachineFile):\n",
    "    n_img_channels = 2\n",
    "    \n",
    "    def set_base_directory(self):\n",
    "        return basedir\n",
    "    \n",
    "    def construct_image_directory(self):\n",
    "        lane_dir = \"Lane{lane_num:0>1}\".format(lane_num = self.lane_num)\n",
    "        pos_dir = \"pos{pos_num:0>1}\".format(pos_num = self.pos_num)\n",
    "        return os.path.join(self.basedir, lane_dir, pos_dir)\n",
    "\n",
    "    def construct_filename(self):\n",
    "        # currently using a file_num as a hack for including fluor files\n",
    "        if self.img_channel == 0:\n",
    "            return \"sb27_pos{pos_num:0>1}-r_raw-{t_frame:0>3}.tif\".format(pos_num = self.pos_num, t_frame = self.t_frame)\n",
    "        elif self.img_channel == 1:\n",
    "            return \"sb27_pos{pos_num:0>1}-g_raw-{t_frame:0>3}.tif\".format(pos_num = self.pos_num, t_frame = self.t_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome, I am done and am ready to verify my MotherMachineFile class is defined correctly [Check MotherMachineFile](#Check-MotherMachineFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that the stanadard segmentation isn't working that well when the cells enter stationary phase in this example, around timepoints > 80. Consider adjusting the default settings for the extract_connected_components_standard.\n",
    "hint: it is combinding lineages together, so consider reducing the maxima smoothing parameter ... you can also try to play with other maxima parameters to get more agressive watershed cutting, it also clogs, so to do it properly you need to crop the image in your extract_conn_comps_func, consider definining a simple custom function using the standard function as the basis, but that also includes a cropping step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basedir = os.path.join(example_base_dir,'example2')\n",
    "\n",
    "def generate_save_directory(lane_num):\n",
    "    save_dir = os.path.join(basedir, \"Lane_{lane_num:0>2}\".format(lane_num = lane_num))\n",
    "    return save_dir\n",
    "\n",
    "class MotherMachineFile(AbstractMotherMachineFile):\n",
    "    n_img_channels = 1\n",
    "    \n",
    "    def set_base_directory(self):\n",
    "        return basedir\n",
    "    \n",
    "    def construct_image_directory(self):\n",
    "        lane_dir = \"Lane_{lane_num:0>2}\".format(lane_num = self.lane_num)\n",
    "        pos_dir = \"pos_{pos_num:0>3}\".format(pos_num = self.pos_num)\n",
    "        return os.path.join(self.basedir, lane_dir, pos_dir)\n",
    "\n",
    "    def construct_filename(self):\n",
    "        # currently using a file_num as a hack for including fluor files\n",
    "        if self.img_channel == 0:\n",
    "            return \"SB7--GC_EXIT_4_MEDIA_001_pos_{pos_num:0>3}_t{t_frame:0>4}_c_MCHERRY.tiff\".format(pos_num = self.pos_num,t_frame = self.t_frame)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome, I am done and am ready to verify my MotherMachineFile class is defined correctly [Check MotherMachineFile](#Check-MotherMachineFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check MotherMachineFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below, if you see the correct filename followed by a matrix, your class is probably reasonable, if you get a bunch of errors, you probably defined your class wrong or you chose a lane, pos, t_frame or img_channel that doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set these values to ones you know exist\n",
    "lane_num = 1\n",
    "pos_num = 2\n",
    "t_frame = 1\n",
    "img_channel = 0\n",
    "s_file = MotherMachineFile(lane_num,pos_num,t_frame)\n",
    "print(\"Is this your filename: \\n\\n\" + s_file.fullfile)\n",
    "print(\"\\n Do you see a reasonable matrix below? \\n\")\n",
    "s_file.getImage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am a champ and everything looks sweet. I am ready to specify the lanes, positions and time frames for analysis [specify](#Specify-lanes,-positions-and-time-frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify lanes, positions and time frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these are somewhat experimental ways to find all the lanes, positions and time_points for your data using the mother machine file you define\n",
    "# this should also tell you whether you messed up when specifying your filenames, if this doesn't show anything below, you probably messed up\n",
    "lane_pos_time_list = detect_image_directories(MotherMachineFile)\n",
    "lane_indcs, pos_indcs, tindcs = find_shared_lane_pos_time_indcs(lane_pos_time_list)\n",
    "lane_indcs, pos_indcs, tindcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if the above didn't work but you are sure everything is normal you can specify them manually below\n",
    "#lane_indcs= [...], pos_indcs = [...], tindcs=[...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Everything is looking good. I am ready to startup a parallel environment with dask. [dask](#Start-Dask-Client)\n",
    "* I am a really inquisitive person, tell me about the standard connected components extraction function [details](#Definition-of-standard-conn-comp-extraction-function)\n",
    "* Actually, I am an expert and want to specify a cusom connected component extraction function [define](#define-any-custom-conn-comp-extraction-function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If analyzing already extracted data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load old data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load old parameters (if not calculating new properties)\n",
    "##### only if using previously calculated and saved properties #####\n",
    "# you should define this generate_load_directory and basedir below\n",
    "\n",
    "# basedir='...'\n",
    "def generate_load_directory(lane_num):\n",
    "    load_dir = os.path.join(basedir, \"Lane{0:0>1}\".format(lane_num))\n",
    "    return load_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load old parameters (if not calculating new properties)\n",
    "##### only if using previously calculated and saved properties #####3\n",
    "\n",
    "lanes_to_load = [1]\n",
    "props_all = pd.DataFrame()\n",
    "\n",
    "for lane in lanes_to_load:\n",
    "    root_dir = generate_load_directory(lane)\n",
    "    props_all = props_all.append(load_properties(os.path.join(root_dir, 'props_all.pkl')),ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connected Component Extraction Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of standard conn comp extraction function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The standard extraction function is called extract_connected_components_standard. It involves finding a rough segmentation using a global otsu threshold and substantial dilation. By multiplying the subsequent segmentation by this rough_thresh, background junk is removed. The main segementation is an auto-local-threshold on a gaussian smoothed image using the niblack method. Next, the centroids ('maxima' in the function) of each cells are found using an auto-local-threshold on a gaussian smoothed image using a niblack method, but with a much smaller niblack window. These are fed into a special watershed algorithm that spits out connected components. This segementation can be tuned by specifying the named parameters, for example by using a higher init_smooth_sigma for noisier images. Alternatively, a completely different segmentation algorithm can be devised. For the pipeline, you just need to provide a connected components matrix to the extract_cells function (as well as the MotherMachineFile used for segmentation and any additional fluorescent MotherMachinefiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define any custom conn comp extraction function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where you will specify any non-standard function for extracting components\n",
    "Normally you will not need to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract_connected_components_func = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Dask Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask is library that sets up the parallelization. You start a client that runs several workers, called a 'cluster'.\n",
    "If running locally, set run_local=True. \n",
    "Also, you can specify the initial number of workers to spawn. \n",
    "If running locally the max number of workers is the number of cpu cores. \n",
    "If running on cluster, the n_workers_init is just the initial number of workers to spawn (keep this small!!!!). You are going to want to test all your settings and run a small extraction using a small subset of your data before scaling to a large number of workers. You can scale up or down as will be shown below.\n",
    "You can also see the active processing by clicking the link next to Dashboard (assuming you are on the correct network)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_local = True\n",
    "n_workers_init = 6\n",
    "\n",
    "if run_local:\n",
    "    client = Client()\n",
    "    client.cluster.scale(n_workers_init)\n",
    "    time.sleep(0.5) # allow client time to respond to scaling before display\n",
    "else:\n",
    "    # note the specifed walltime, don't use too much or too little, 01:30:00 is a good baseline, \n",
    "    # you just need enough time to finish 'gathering' to props_all before the jobs die\n",
    "    # you can always spin up more jobs later\n",
    "    # you will launch many jobs, so you don't need multiple processes, a lot of ram or multiple threads\n",
    "    cluster = SLURMCluster(queue=\"short\",walltime='01:30:00',job_cpu=1,job_mem='6G',threads=1,processes=1,memory='6GB')\n",
    "    cluster.start_workers(n_workers_init)\n",
    "    client = Client(cluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything looks good, proceed through each of the sections below. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine optimal connected component extraction settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class is designed to provide a way to play with the parameters of a standard connected components extraction procedure, i.e. one that uses the parameters (init_niblack_k, maxima_niblack_k, init_smooth_sigma, maxima_smooth_sigma, init_niblack_window_size, maxima_niblack_window_size). <br> <br>\n",
    "Note: the plot may take up to a minute to initially load and may spit out a warning before appearing (ignore this, there is a bug in the holoviews code). <br> <br> Also Note: the colors do not indicate lineages, i.e. it is expected to change as you go through t-frames, the colors are just used to distinguish connected components within a single image. Also, identical colors do not necessarily indicate they are the same region.<br> <br>\n",
    "Finally: it is supposed to start out zoomed in on part of the image, use the tools to zoom or move around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify a subset of all tindcs for speed\n",
    "tindcs_to_plot = np.sort(np.random.choice(tindcs,size=15,replace=False))\n",
    "conn_comp_plotter = PlotConnCompSettings(lane_indcs, pos_indcs, tindcs_to_plot, MotherMachineFile,\n",
    "                                         extract_connected_components_standard, client, has_two_lanes = True)\n",
    "conn_comp_plotter.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Connected Components\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines the run_extraction function for doing parallel extraction of a list of dictionary containing region props for all connected components found with the connected_components_func. All that is needed is MotherMachineFile object, corresponding connected component (or procedure for generating one). <br>\n",
    "\n",
    "use_parameters_from_plot = [True,False] : if True, then the optional parameters specified by the conn_comp_plotter settings shown in the plots above will be used, otherwise it will use defaults. <br> <br>\n",
    "props_to_grab = ['all','min','supp'] : (advanced-users only) if you specify min, it will only gather a smaller set of parameters, this can be a lot faster but you won't get all the useful parameters at the end, i.e. solidity, convex hull, etc. Only really helpful it you have a very large number of regions you won't need to filter with advanced properties later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_parameters_from_plot = True\n",
    "props_to_grab = 'all' #choose ['all','min','supp] (default: 'all', only use if you know what you are doing)\n",
    "\n",
    "if use_parameters_from_plot:\n",
    "    kwargs = (conn_comp_plotter.recC.kwargs.copy())\n",
    "    print(\"Using these parameters for analysis: \\n\")\n",
    "    print(kwargs)\n",
    "    extract_conn_comp = conn_comp_plotter.extract_conn_comp_func\n",
    "    def extract_connected_components_func(img):\n",
    "        return extract_conn_comp(img, **kwargs)\n",
    "\n",
    "n_img_channels = MotherMachineFile.n_img_channels\n",
    "\n",
    "def run_extraction(lane_num, pos_num, t_frame):\n",
    "    s_file = MotherMachineFile(lane_num,pos_num,t_frame)\n",
    "    f_files = [MotherMachineFile(lane_num, pos_num, t_frame, i) for i in range(1, n_img_channels)]\n",
    "    conn_comp = extract_connected_components_func(s_file.getImage())\n",
    "    return extract_cells(s_file, conn_comp, fluorescent_files = f_files, props_to_grab = props_to_grab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters lane_num_to_analyze, pos_indcs_to_analyze, t_indcs_to_analyze will specify which lanes, positions, and time frames you want to analyze. If you are running on the cluster, the parameter scale_workers will specify the number of jobs to launch total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### specify me !!!!!!! #####\n",
    "lane_num_to_analyze = lane_indcs[0]\n",
    "pos_indcs_to_analyze = pos_indcs[0:2]\n",
    "t_indcs_to_analyze = tindcs[0:30]\n",
    "scale_workers = 0 # set to zero if running locally\n",
    "#### end specify me !!!!!!! #####\n",
    "\n",
    "if scale_workers > 0:\n",
    "    cluster.scale(scale_workers)\n",
    "    \n",
    "futures = []\n",
    "for pos_num in pos_indcs_to_analyze:\n",
    "    \n",
    "    def extract(t_frame):\n",
    "        return run_extraction(lane_num_to_analyze,pos_num,t_frame)\n",
    "    \n",
    "    fut = client.map(extract,t_indcs_to_analyze)\n",
    "    futures.append(fut)\n",
    "\n",
    "all_futures = [f for sublist in futures for f in sublist]\n",
    "\n",
    "dask.distributed.progress(all_futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## put properties into pandas dataframe and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## combine all results together ##\n",
    "# by combining in a loop, ram usage is minimized\n",
    "\n",
    "props = client.gather(futures[0])\n",
    "flat_props = [item for sublist in props for item in sublist]\n",
    "props_all = pd.DataFrame(flat_props)\n",
    "int_dtype_list = props_all.select_dtypes(include=np.int64).dtypes.index.tolist()\n",
    "props_all[int_dtype_list] = props_all[int_dtype_list].astype(np.uint16)\n",
    "\n",
    "for i in range(1,len(futures)):\n",
    "    props = client.gather(futures[i])\n",
    "    flat_props = [item for sublist in props for item in sublist]\n",
    "    add_props = pd.DataFrame(flat_props)\n",
    "    add_props[int_dtype_list] = add_props[int_dtype_list].astype(np.uint16)\n",
    "    props_all = props_all.append(add_props,ignore_index=True)\n",
    "    \n",
    "print(\"mem used: %2.3f\" % (int(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)/(10**6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now have your result! Awesome! <br>\n",
    "It is in a pandas dataframe called props_all. I have included some basic commands to verify that the extraction worked. <br>\n",
    "You should also checkout the pandas docs to get a sense of the cool things you can do with that dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some helpful funtions to verify that the extraction worked correctly\n",
    "# uncomment one at a time to view them\n",
    "\n",
    "### show first few lines\n",
    "props_all.head()\n",
    "\n",
    "### show descriptive statistics for all of the columns\n",
    "#props_all.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I highly recommend saving your result. <br>\n",
    "Verify the save directory is correct below, then save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_dir = generate_save_directory(lane_num)\n",
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_properties(props_all, os.path.join(save_dir, \"props_all.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze and filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "property_bounds_dict = {}\n",
    "property_bounds_dict['area'] = [14,10000]\n",
    "# property_bounds_dict['solidity'] = [0.8,  1.0] # just an example of the types of bounds that can be specified\n",
    "\n",
    "start = timer()\n",
    "props_clean = select_cells_in_trenches(props_all,trenchLocs = TrenchLocs.TOP_AND_BOTTOM, below_trench_quantile=70,above_trench_quantile=90,mother_cell_y_offset=15)\n",
    "props_clean = select_reasonable_cells(props_clean,property_bounds_dict)\n",
    "end = timer()\n",
    "\n",
    "print(\"time elapsed: %2.3f\" % (end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show all the centroids from all the positions z-stacked on top of eachother"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualization can be used to verify that the correct filtering was applied above, i.e. if the dots are too tight in the y-direction, relax the quantiles, if they are too loose tigthen them, etc. Go back to [filter](#Analyze-and-filter-data) and tweak until you are happy with the result. <br><br>\n",
    "When you are happy with the extent of centroids continue on to plot them overlayed on the images as a final sanity check. <br><br>\n",
    "You can either plot the convex hull, which is very fast and should give you essentially the information you need, or you can scatter all the centroids which is slow and ram intensive but gives more detail. Unless something is broken, use quick_plot=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width, img_height = props_clean.iloc[0].img_width, props_clean.iloc[0].img_height\n",
    "img_width_scaled = int(0.65*img_width)\n",
    "img_height_scaled = int(0.65*img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%opts Scatter [title_format='z-stacked centroids' width=img_width_scaled height=img_height_scaled invert_yaxis=True fontsize={'title':30, 'xlabel':10, 'ylabel':10, 'ticks':10}] (size=10)\n",
    "%%opts Curve [title_format='z-stacked centroids convex hull' width=img_width_scaled height=img_height_scaled invert_yaxis=True fontsize={'title':30, 'xlabel':10, 'ylabel':10, 'ticks':10}]\n",
    "\n",
    "quick_plot = True\n",
    "\n",
    "if quick_plot:\n",
    "    def plot_hulls(pos_num):\n",
    "        tims = np.unique(props_clean.trench_inversion_mult.values)\n",
    "        p=[]\n",
    "        for tim in tims:\n",
    "            to_select = np.all((props_clean.trench_inversion_mult == tim, props_clean.pos_num == pos_num),axis=0)\n",
    "            cents = props_clean.loc[to_select,['centx','centy']].values\n",
    "            hull = ConvexHull(cents)\n",
    "            verts = np.append(hull.vertices,hull.vertices[0])\n",
    "            p.append(hv.Curve((cents[verts,0], cents[verts,1])))\n",
    "        return reduce(lambda x,y: x*y, p)\n",
    "        \n",
    "    curve_dict = {pos_num:plot_hulls(pos_num) for pos_num in np.unique(props_clean.pos_num.values).tolist()}\n",
    "    to_plot = hv.HoloMap(curve_dict,kdims='pos_num').redim(x={'range':(0,img_width)},y={'range':(0,img_height)})\n",
    "\n",
    "else:\n",
    "    ds_props = hv.Dataset(props_clean)\n",
    "    to_plot = ds_props.to(hv.Scatter,'centx','centy',groupby=['pos_num']).overlay().redim(centx={'range':(0,img_width)},centy={'range':(0,img_height)})\n",
    "    \n",
    "    \n",
    "to_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot filtered connected components and centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plots the connected components pulled directly from your 'props_clean' pandas dataframe. This is the baseline truth of what is in your data. <br> <br>\n",
    "It also overlays the centroids for the connected components. Missing cells at the bottom are expected (you filtered them out above). <br> <br>\n",
    "If you are not keeping the correct amount of cells, you need to go back to [filter](#Analyze-and-filter-data).\n",
    "If you are missing mother cells, you need to adjust either the mother_cell_offset or above_trench_quantile. If you have too few daughter cells adjust below_trench_quantile.\n",
    "\n",
    "Once again, the colors are only indicative of connected components in a single image, they don't indicate lineages across time. i.e. it is expected that a mother cell will change color as it moves through lineages, don't panic! We haven't found lineages yet afterall, that will happen below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lanes_analyzed = np.unique(props_clean.lane_num)\n",
    "pos_analyzed = np.unique(props_clean.pos_num)\n",
    "t_indcs_analyzed = np.unique(props_clean.t_frame)\n",
    "conn_comp_results = PlotConnCompResults(lanes_analyzed, pos_analyzed, t_indcs_analyzed,props_clean)\n",
    "conn_comp_results.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort properties into lineages based on positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = timer()\n",
    "props_sort = sort_cells_into_lineages(props_clean)\n",
    "props_sort = determine_position_of_cell_in_trench(props_sort)\n",
    "props_sort = create_linear_index(props_sort)\n",
    "end = timer()   \n",
    "print(\"time elapsed: %2.3f\" % (end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot trenches to make sure they are correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same as the plots from above, but now the cells are colored by lineage, rather than connected component. You can tell whether two cells have been seperated by whether they have a centroid plotted on top of them, i.e. even if they look connected, if all the cells have centroids plotted on them, they have been detected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lanes_analyzed = np.unique(props_sort.lane_num)\n",
    "pos_analyzed = np.unique(props_sort.pos_num)\n",
    "t_indcs_analyzed = np.unique(props_sort.t_frame)\n",
    "conn_comp_results = PlotConnCompResults(lanes_analyzed, pos_analyzed, t_indcs_analyzed,props_sort)\n",
    "conn_comp_results.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the convex hull of the centroids for a given lineage z-stacked through time for each position. The color should indicate the lineage. On top of that hull, is a point that gives the details for each lineage. <br> <br> \n",
    "Note: There seems to be a weird bug where the first time you go to a position, some hulls are white, just go forward a position and come back. <br>\n",
    "Note: The initial zoom is currently a bit weird, you will need to zoom out. <br>\n",
    "Also: You can zoom the axes independently by selecting the zoom tool and putting the cursor overtop of the axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%opts Scatter [title_format='hull of lineage centroids positions' width=int(img_width) height=200 invert_yaxis=True fontsize={'title':15, 'xlabel':10, 'ylabel':10, 'ticks':10}] (size=6) {+axiswise}\n",
    "%%opts Curve [width=int(img_width) height=200 invert_yaxis=True fontsize={'title':5, 'xlabel':10, 'ylabel':10, 'ticks':10}] {+axiswise}\n",
    "\n",
    "n_trench_pos = len(props_sort.trench_inversion_mult.unique())\n",
    "n_lineages_max = props_sort.lineage_idx.max()\n",
    "plot_colors=hv.plotting.util.process_cmap('jet',ncolors=5)\n",
    "\n",
    "def plot_lineage_hulls(pos_num):\n",
    "    t_tips = [(\"centx\", \"@centx\"),(\"centy\", \"@centy\"),(\"area\", \"@area\"),\n",
    "              (\"solidity\", \"@solidity\"),(\"label\",\"@label_orig\"),(\"lineage\",\"@linear_lineage_idx\")]\n",
    "\n",
    "    vdims = [\"centx\",\"centy\",\"area\",\"solidity\",\"pos_num\",\"lineage_idx\",\"linear_lineage_idx\"]\n",
    "    hv_plot_list = []\n",
    "    for trench_mult in np.unique(props_sort.trench_inversion_mult.values).tolist():\n",
    "        to_select = np.all([props_sort.pos_num == pos_num, props_sort.trench_inversion_mult == trench_mult],axis=0)\n",
    "        ps = props_sort[to_select]\n",
    "        lin_idx = np.unique(ps.lineage_idx.values)\n",
    "        p=[]\n",
    "        centx=[]\n",
    "        for lineage in lin_idx:\n",
    "            to_select_lineage = ps.lineage_idx == lineage\n",
    "            cents = ps.loc[to_select_lineage,['centx','centy']].values\n",
    "            hull = ConvexHull(cents)\n",
    "            verts = np.append(hull.vertices,hull.vertices[0])\n",
    "            centx.append(np.mean(cents[verts,0]))\n",
    "            p.append(hv.Curve((cents[verts,0], cents[verts,1])))\n",
    "\n",
    "        p = [p[sb] for sb in np.argsort(centx)]\n",
    "        ps_no_obj = ps.select_dtypes(exclude=np.object).copy()\n",
    "        ps_no_obj['lineage_keys'] = ps_no_obj['linear_lineage_idx']\n",
    "        ps_mean = ps_no_obj.groupby('lineage_keys').mean()\n",
    "        ps_dataset = hv.Dataset(ps_mean,['centx','centy'],vdims=vdims)\n",
    "        hover = HoverTool(tooltips=t_tips)\n",
    "        hover.point_policy = 'snap_to_data'\n",
    "        hv_cents = ps_dataset.to(hv.Scatter).opts(plot=dict(tools=[hover], color_index='lane_num'))\n",
    "        p_hull = reduce(lambda x,y: x*y, p)\n",
    "        hv_plot_list.append(hv_cents*p_hull)\n",
    "        \n",
    "    hv_plot = reduce(lambda x,y: x+y, hv_plot_list)\n",
    "    return hv_plot.cols(1)\n",
    "\n",
    "pos_nums = np.unique(props_sort.pos_num.values).tolist()\n",
    "curve_dict = {pos_num:plot_lineage_hulls(pos_num) for pos_num in pos_nums}\n",
    "to_plot = hv.HoloMap(curve_dict,kdims='pos_num').redim(x={'range':(0,img_width)})\n",
    "to_plot.options({'Curve':dict(color=hv.Cycle(plot_colors)),'Scatter':dict(color='black')}).collate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reorganize, clean and analyze lineages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## index by lineages, remove bad lineages, calculate division properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will help filter out bad lineages, i.e. those that are probably multiple lanes fused together and those that have too many nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mother_props = stack_mother_properties(props_sort)\n",
    "# drop lineages with more more than max_frac_nan area measurements\n",
    "max_frac_nan = 0.9\n",
    "\n",
    "not_too_many_nulls = mother_props.area.notnull().sum() > mother_props.shape[0]*max_frac_nan\n",
    "\n",
    "# remove lineages that contain two (or more) trenches grouped together during clustering\n",
    "standard_trench_width = np.median(mother_props.centx.max() - mother_props.centx.min())\n",
    "normal_width_lineages = mother_props.centx.max() - mother_props.centx.min() < 2*standard_trench_width\n",
    "\n",
    "good_lineages = np.where(np.all([not_too_many_nulls,normal_width_lineages],axis=0))[0]\n",
    "\n",
    "props_filtered = props_sort[props_sort['linear_lineage_idx'].isin(good_lineages)].copy()\n",
    "props_filtered = cleanup_lengths(props_filtered,cutoff_scale=0,minimum_peak_height=12)\n",
    "props_filtered = calculate_and_append_divisions(props_filtered)\n",
    "props_filtered = calculate_and_append_divisions(props_filtered,peak_column='major_axis_length_corrected',suffix='_corrected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mom_props_filtered = props_filtered[props_filtered.cell_pos == 0]\n",
    "dataset = hv.Dataset(mom_props_filtered.drop(['bbox','intensity_image'],axis=1))\n",
    "\n",
    "q_dividing_cells = (mom_props_filtered[['is_dividing_corrected','linear_lineage_idx']].groupby('linear_lineage_idx').sum() > 0).values\n",
    "dividing_cells = np.where(q_dividing_cells[:,0])[0].tolist()\n",
    "dividing_mothers = mom_props_filtered[mom_props_filtered['linear_lineage_idx'].isin(dividing_cells)]\n",
    "dividing_dataset = hv.Dataset(dividing_mothers.drop(['bbox','intensity_image'],axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot traces and divisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the simple way in which your data can be easily plotted for various features, it is very minimal code for a pretty complex plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%opts Curve [width=700 height=300 invert_yaxis=False fontsize={'title':15, 'xlabel':10, 'ylabel':10, 'ticks':10}] {+axiswise}\n",
    "%%opts Scatter (size=10,color='green')\n",
    "\n",
    "hv_plot = dividing_dataset.to(hv.Curve,'t_frame','major_axis_length_corrected',groupby='linear_lineage_idx',dynamic=True).options(color='b')\n",
    "hv_plot_un = dividing_dataset.to(hv.Curve,'t_frame','major_axis_length',groupby='linear_lineage_idx',dynamic=True).options(color='r')\n",
    "new_dataset = dividing_dataset.iloc[dividing_dataset['is_dividing_corrected'].tolist(),:]\n",
    "\n",
    "hv_scatter = new_dataset.to(hv.Scatter, 't_frame','major_axis_length_corrected',groupby='linear_lineage_idx',dynamic=True)\n",
    "hv_scatter*hv_plot_un*hv_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A montage showing the mother cells and it's major axis length, as well as the found division times. The corrected major axis length is in blue and the original is in red, which will obviously only show up when you have a corrected timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%opts Curve [width=1000 height=300 invert_yaxis=False fontsize={'title':15, 'xlabel':10, 'ylabel':10, 'ticks':10}] {+axiswise}\n",
    "%%opts Image [width=1000 height=300 invert_yaxis=False fontsize={'title':15, 'xlabel':10, 'ylabel':10, 'ticks':10}] {+framewise}\n",
    "%%opts Scatter (size=10)\n",
    "\n",
    "lindcs = np.unique(props_filtered.linear_lineage_idx)\n",
    "nan_frames = np.nan*np.ones((t_indcs_analyzed.shape[0]+1,))\n",
    "\n",
    "def make_montage(lidx,t):\n",
    "    ps = mom_props_filtered[mom_props_filtered.linear_lineage_idx == lidx]\n",
    "    int_images = ps.intensity_image\n",
    "    t_frames = ps.t_frame.tolist()\n",
    "    t_frames_filled = nan_frames.copy()\n",
    "    t_frames_filled[t_frames] = t_frames\n",
    "    t_frames_filled = pd.Series(t_frames_filled).fillna(method='ffill')\n",
    "    t_frames_filled = t_frames_filled.fillna(method='bfill').astype(np.int16)\n",
    "    t_plot = t_frames_filled.iloc[t]\n",
    "    \n",
    "    c = 'b' if (t in t_frames) else 'r'\n",
    "    t_final = np.where(t_frames == t)[0][0]+1\n",
    "    img = make_cell_montage(np.array(int_images)[0:t_final],n_cols=50)\n",
    "    h, w = img.shape[0], img.shape[1]\n",
    "    \n",
    "    hv_img = hv.Image(img,extents=(0,0,w,300),bounds=hv.BoundingBox(points=((0,0),(w,(1000/w)*h))))\n",
    "    \n",
    "    hv_sel = dataset.select(linear_lineage_idx=[lidx],cell_pos=0)\n",
    "    hv_sel['major_axis_length']\n",
    "    hv_curve = hv_sel.to(hv.Curve,'t_frame','major_axis_length',groupby='linear_lineage_idx').options(color='r').values()[0]\n",
    "    hv_curve_cor = hv_sel.to(hv.Curve,'t_frame','major_axis_length_corrected',groupby='linear_lineage_idx').options(color='b').values()[0]\n",
    "\n",
    "    hv_diff = hv_sel.to(hv.Curve,'t_frame','major_axis_length',groupby='linear_lineage_idx').values()[0]\n",
    "\n",
    "    \n",
    "    \n",
    "    hv_scat = dataset.select(linear_lineage_idx=[lidx],cell_pos=0,t_frame=t_plot)\n",
    "    hv_scat = hv_scat.to(hv.Scatter,'t_frame','major_axis_length',groupby=['linear_lineage_idx']).opts(style=dict(color=c)).values()[0]\n",
    "    \n",
    "    return (hv_img + hv_curve*hv_curve_cor*hv_scat).cols(1)\n",
    "\n",
    "kdims = [hv.Dimension(\"lineage\",values=lindcs),\n",
    "         hv.Dimension(\"t_frame\",values=t_indcs_analyzed)]\n",
    "dmap = hv.DynamicMap(make_montage,kdims=kdims)\n",
    "dmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_dir = generate_save_directory(lane_num)\n",
    "save_properties(props_all, os.path.join(save_dir, \"props_all.pkl\"))\n",
    "save_properties(props_filtered, os.path.join(save_dir, \"props_filtered.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
